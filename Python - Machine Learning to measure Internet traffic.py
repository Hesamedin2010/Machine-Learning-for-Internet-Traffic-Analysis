# # Machine Learning to measure Internet traffic

'''
In this analysis, I am going to use different aspects of Machine Learning applied to a Big Data framework.
I will apply classification and clustering techniques to measure the Internet traffic.
A network log trace file summarizing the traffic generated by thousands of users while browsing the web is used.

A Tstat (TCP STatistic and Analysis Tool) log file will be used.
Each line represents a TCP connection. Besides the connection identifiers (client and server
IP addresses and ports), Tstat reports dozens of features, such as the number of packets,
bytes uploaded and downloaded, etc.
'''

# Input Data from the big data cluster
Tstat = "/data/students/bigdata_internet/lab4/log_tcp_complete_classes.txt"

'''In this analysis, PySpark was utilized for its robust distributed computing capabilities, 
ideal for handling large datasets efficiently.
If you're using the PySpark shell, no additional setup is necessary. 
However, for those working in a Python environment, setting up PySpark involves the following steps:
1. Install PySpark: Begin by installing PySpark using pip:
pip install pyspark
2. Configure PySpark.sql: In your Python script or interactive session, include the following configuration 
to initialize PySpark.sql:
```python
from pyspark.sql import SparkSession
spark = SparkSession.builder.getOrCreate()
```
Ensure to execute this configuration before performing any PySpark operations.
For comprehensive installation and configuration instructions, refer to the official PySpark documentation: 
PySpark Installation Guide
'''

# Reading data
spark = SparkSession.builder.getOrCreate()
df = spark.read.load(Tstat, format="csv", header=True, inferSchema=True, sep=' ')

# See the columns of our dataframe
df.columns

# Count the number of columns. There are 207 columns
len(df.columns)

# Count the number of rows. There are 100,000 rows which means 100,000 TCP connections
df.count()

# The 207th column "class:207" there are the label of classes
class_207 = df.select("class:207")

# There are 10 classes in this TCP connection dataframe
class_207.distinct().count()

# The list of classes can be seen here (such as google, amazon, etc.)
class_207.distinct().show()

# I am going to group the dataframe by classes and count the number of TCP connections to see how much connection
# we have for each class

web_services = df.groupBy("class:207").count()
web_services.show()

# -------------------------------------------------------------------------------------------

# Classify TCP connections

# Split dataframe into train-set and test-set (75, 25)
trainValidation, test = df.randomSplit([0.75, 0.25], 42)

# Pre-processing the dataset
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.feature import StringIndexer

# Select features
feat_cols = ['c_bytes_uniq:7', 's_bytes_uniq:21', 'c_pkts_data:8', 's_pkts_data:22']

# Preprocess TrainValidation set
# Vector Assembler
va = VectorAssembler(inputCols=feat_cols, outputCol='features')
vDF = va.transform(trainValidation)
# Convert string to index for target column
indexer = StringIndexer(inputCol="class:207", outputCol="label")
indexerModel = indexer.fit(vDF)
indexedDF = indexerModel.transform(vDF)

# Preprocess Test set
testVDF = va.transform(test)
testIndexedDF = indexerModel.transform(testVDF)

# -------------------------------------------------------------------------------------------

# For classification, I am going to use Decision Tree model and Random Forest model
# In order to compare how much time do these models take to train the I will import time to compare them
import time

# 1. DECISION TREE CLASSIFIER
from pyspark.ml.classification import DecisionTreeClassifier
dt = DecisionTreeClassifier(labelCol="label", featuresCol="features", maxDepth=20)
start_time = time.time()
dtModel = dt.fit(indexedDF)
stop_time = time.time()
print(f'It takes {stop_time - start_time} seconds')
finalDFdt = dtModel.transform(indexedDF)

testDFdt = dtModel.transform(testIndexedDF)


# 2. RANDOM FOREST CLASSIFIER
from pyspark.ml.classification import RandomForestClassifier
rf = RandomForestClassifier(labelCol="label", featuresCol="features", numTrees=20, maxDepth=20)
start_time = time.time()
rfModel = rf.fit(indexedDF)
stop_time = time.time()
print(f'It takes {stop_time - start_time} seconds')
finalDFrf = rfModel.transform(indexedDF)

testDFrf = rfModel.transform(testIndexedDF)

# -------------------------------------------------------------------------------------------

# Evaluate the performance of the models

'''The result shows that Random Forest classifies data a little bit easier, because the precision of 
its classes are more diverse (0.50, 0.84) and this range is smaller for Decision Tree (0.50, 0.79).
For train set, Decision Tree classifier's accuracy is a little bit more than Random Forest Classifier 
but in the test set, the accuracy of Random Forest is a little more than Decision Tree.'''

# Evaluate the Decision Tree model performance
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
accuracy = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="accuracy")

# Global accuracy on the TrainValidation set
print(f'Decition Tree Train Model:\t accuracy = {accuracy.evaluate(finalDFdt)}\nRandom Forest Train Model:\t accuracy = {accuracy.evaluate(finalDFrf)}')

# Global accuracy on the Test set
print(f'Decition Tree Train Model:\t accuracy = {accuracy.evaluate(testDFdt)}\nRandom Forest Train Model:\t accuracy = {accuracy.evaluate(testDFrf)}')

dtTestRDD = testDFdt.select("prediction", "label").rdd.map(lambda x: (float(x[0]), float(x[1])))
rfTestRDD = testDFrf.select("prediction", "label").rdd.map(lambda x: (float(x[0]), float(x[1])))

from pyspark.mllib.evaluation import MulticlassMetrics

def metrics_calculator(x):
    metrics = MulticlassMetrics(x)
    precision = metrics.precision()
    recall = metrics.recall()
    f1Score = metrics.fMeasure
    labels = x.map(lambda a: a[1]).distinct().collect()
    print("Class \t Precision \t\t Recall \t\t F1Score")
    for label in sorted(labels):
        print(f'{label},\t {metrics.precision(label)},\t {metrics.recall(label)},\t {metrics.fMeasure(label, beta=0.1)}')

dtTestMetrics = metrics_calculator(dtTestRDD)

rfTestMetrics = metrics_calculator(rfTestRDD)

# -------------------------------------------------------------------------------------------

# Hyper-parameters tuning

# I am going to use CrossValidation and ParamGridBuilder for tuning
from pyspark.ml.tuning import CrossValidator
from pyspark.ml.tuning import ParamGridBuilder

# Decision Tree parameter Tuning
dtParamGrid = ParamGridBuilder().addGrid(dt.maxDepth, [15, 20, 25]).addGrid(dt.impurity, ["Gini", "Entropy"]).build()
# CrossValidation
dtCv = CrossValidator(estimator=dt, evaluator=accuracy, estimatorParamMaps=dtParamGrid, numFolds=3)
dtCvModel = dtCv.fit(indexedDF)
dtFinalDF = dtCvModel.transform(indexedDF)

import numpy as np
# Analyze the best parameter of Decision Tree Classifier
dtCvModel.getEstimatorParamMaps()[np.argmax(dtCvModel.avgMetrics)]

# Random Forest parameter Tuning
rfParamGrid = ParamGridBuilder().addGrid(rf.maxDepth, [15, 20, 25]).addGrid(rf.impurity, ["Gini", "Entropy"]).addGrid(rf.numTrees, [15, 20, 25]).build()
# CrossValidation
rfCv = CrossValidator(estimator=rf, evaluator=accuracy, estimatorParamMaps=rfParamGrid, numFolds=3)
rfCvModel = rfCv.fit(indexedDF)
rfFinalDF = rfCvModel.transform(indexedDF)

# Analyze the best parameter of Decision Tree Classifier
rfCvModel.getEstimatorParamMaps()[np.argmax(rfCvModel.avgMetrics)]

# Calculate best Decision Tree model accuracy
bestDT = DecisionTreeClassifier(labelCol="label", featuresCol="features", maxDepth=20, impurity="Gini")
bestDTModel = bestDT.fit(indexedDF)
bestDTFinal = bestDTModel.transform(indexedDF)
accuracy.evaluate(bestDTFinal)

# Calculate best Random Forest model accuracy
bestRF = RandomForestClassifier(labelCol="label", featuresCol="features", maxDepth=20, impurity="Gini", numTrees=20)
bestRFModel = bestRF.fit(indexedDF)
bestRFFinal = bestRFModel.transform(indexedDF)
accuracy.evaluate(bestRFFinal)

# Calculate best Decision Tree model accuracy test set
bestDTFinaltest = bestDTModel.transform(testIndexedDF)
accuracy.evaluate(bestDTFinaltest)

# Calculate best Random Forest model accuracy test set
bestRFFinaltest = bestRFModel.transform(testIndexedDF)
accuracy.evaluate(bestRFFinaltest)

# It shows that the best possible model is Random Forest and its accuracy is about 70% 

# -------------------------------------------------------------------------------------------

# Clustering users

# I am going to use k-means model and Gaussian mixture model

# Calculate how many distinct IPs (users) we have
clients = df.select("#31#c_ip:1").distinct().count()
print(clients)

# Find the top-5 most active users
connections = df.groupBy("#31#c_ip:1").agg({"#31#c_ip:1": "count", "c_bytes_all:9":"sum", "s_bytes_all:23":"sum", "s_bytes_retx:25":"sum", "s_rtt_avg:52":"avg", "s_first:33":"avg"})
connectionOrdered = connections.sort("count(#31#c_ip:1)", ascending=False).show(5)

# Calculate the average number of connections 
connectionsAvg = connections.agg({"count(#31#c_ip:1)":"avg"})
connectionsAvg.show()

# Features selection
feat_cols_cluster = ['count(#31#c_ip:1)', 'sum(s_bytes_all:23)', 'sum(s_bytes_retx:25)', 'sum(c_bytes_all:9)', 'avg(s_rtt_avg:52)', 'avg(s_first:33)']

# Preprocessing
va_cluster = VectorAssembler(inputCols=feat_cols_cluster, outputCol="features")
assembledDF = va_cluster.transform(connections)
# Scaler
from pyspark.ml.feature import StandardScaler
scaler = StandardScaler(inputCol="features", outputCol="scaledFeatures", withStd=True, withMean=True)
scalerModel = scaler.fit(assembledDF)
scaledDF = scalerModel.transform(assembledDF)

# Train the K-Means model
from pyspark.ml.clustering import KMeans
kmeans = KMeans(k=10, featuresCol="scaledFeatures")
kmeansModel = kmeans.fit(scaledDF)
kmeansPredictionsDF = kmeansModel.transform(scaledDF)

# Train the GMM model
from pyspark.ml.clustering import GaussianMixture
gmm = GaussianMixture(k=10, featuresCol="scaledFeatures")
gmmModel = gmm.fit(scaledDF)
gmmPredictionsDF = gmmModel.transform(scaledDF)

from pyspark.ml.evaluation import ClusteringEvaluator
evaluator = ClusteringEvaluator()

# Evaluate K-Means performance 
silhouetteKMeans = evaluator.evaluate(kmeansPredictionsDF)
print("Silhouette with squared euclidean distance = " + str(silhouette))
print("SSE: ",kmeansModel.computeCost(kmeansPredictionsDF))

# Evaluate GMM performance 
silhouetteGMM = evaluator.evaluate(gmmPredictionsDF)
print("Silhouette with squared euclidean distance = " + str(silhouette))

# Tune K-means Parameters
kmeansBest = KMeans(k=3, featuresCol="scaledFeatures", initSteps=10, maxIter=25)
kmeansModelBest = kmeansBest.fit(scaledDF)
kmeansPredictionsBest = kmeansModelBest.transform(scaledDF)
silhouetteBKM = evaluator.evaluate(kmeansPredictionsBest)
print("Silhouette with squared euclidean distance = " + str(silhouetteBKM))

# Tune the GMM parameters
gmmBest = GaussianMixture(k=3, featuresCol="scaledFeatures", maxIter=5)
gmmModelBest = gmmBest.fit(scaledDF)
gmmPredictionsBest = gmmModelBest.transform(scaledDF)
silhouetteBGMM = evaluator.evaluate(gmmPredictionsBest)
print("Silhouette with squared euclidean distance = " + str(silhouetteBGMM))

