{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c51a26e6-9cbc-483b-8002-84166bb6647e",
   "metadata": {},
   "source": [
    "# Machine Learning to measure Internet traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d459fd2-9602-46ac-a51b-f6faecc7f45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "In this analysis, I am going to use different aspects of Machine Learning applied to a Big Data framework.\n",
    "I will apply classification and clustering techniques to measure the Internet traffic.\n",
    "A network log trace file summarizing the traffic generated by thousands of users while browsing the web is used.\n",
    "\n",
    "A Tstat (TCP STatistic and Analysis Tool) log file will be used.\n",
    "Each line represents a TCP connection. Besides the connection identifiers (client and server\n",
    "IP addresses and ports), Tstat reports dozens of features, such as the number of packets,\n",
    "bytes uploaded and downloaded, etc.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f84452-303c-4da9-afda-0c3b44a63ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Data from the big data cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "398534b5-a03f-4340-88be-8cd1f3cea357",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tstat = \"/data/students/bigdata_internet/lab4/log_tcp_complete_classes.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e396a730-9bbd-49f2-a01d-371170225710",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''In this analysis, PySpark was utilized for its robust distributed computing capabilities, \n",
    "ideal for handling large datasets efficiently.\n",
    "If you're using the PySpark shell, no additional setup is necessary. \n",
    "However, for those working in a Python environment, setting up PySpark involves the following steps:\n",
    "1. Install PySpark: Begin by installing PySpark using pip:\n",
    "pip install pyspark\n",
    "2. Configure PySpark.sql: In your Python script or interactive session, include the following configuration \n",
    "to initialize PySpark.sql:\n",
    "```python\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "```\n",
    "Ensure to execute this configuration before performing any PySpark operations.\n",
    "For comprehensive installation and configuration instructions, refer to the official PySpark documentation: \n",
    "PySpark Installation Guide\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7db4902-b746-42fe-82fb-4c4e18b53b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a005f02-af6c-4a34-8a12-1c5564f2bda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "df = spark.read.load(Tstat, format=\"csv\", header=True, inferSchema=True, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698f5320-6afd-452a-bc28-8063f6045754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the columns of our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92c87e88-2262-4371-8150-e91cccfde2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b3b20e-1189-442d-b494-3cb75ccb0cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of columns. There are 207 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "555a72f7-6ff6-4cf5-adf5-81d1bf1529fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990fd1f9-9b28-42b7-868a-16d73d795a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of rows. There are 100,000 rows which means 100,000 TCP connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9740f4c8-babc-4431-a5df-1c8bfb5d0f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a29dc4d-6688-4a4e-a126-429e57a78eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 207th column \"class:207\" there are the label of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b9c0549-9ea4-4795-a62b-93f468679003",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_207 = df.select(\"class:207\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4118df4-4b38-425f-8816-6e54c6de4f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 10 classes in this TCP connection dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "040ec391-00a6-4a14-9c12-f3d8d3d10e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_207.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7aad3d-bcb6-4f72-a3bf-730b4aa6b99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The list of classes can be seen here (such as google, amazon, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e746b98-a19d-4fcd-8ed7-8bf7af13f858",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|      class:207|\n",
      "+---------------+\n",
      "|   class:google|\n",
      "|   class:amazon|\n",
      "|class:instagram|\n",
      "| class:facebook|\n",
      "|  class:netflix|\n",
      "|     class:ebay|\n",
      "|  class:spotify|\n",
      "| class:linkedin|\n",
      "|  class:youtube|\n",
      "|     class:bing|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_207.distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f625fee6-707a-4b30-8dd7-70086e4a946b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am going to group the dataframe by classes and count the number of TCP connections to see how much connection\n",
    "# we have for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e734eaa-92b0-4602-a7fe-0d3432a88a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_services = df.groupBy(\"class:207\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e869c85f-5ff1-4c28-adbd-3cf0202f3a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|      class:207|count|\n",
      "+---------------+-----+\n",
      "|   class:google|10000|\n",
      "|   class:amazon|10000|\n",
      "|class:instagram|10000|\n",
      "| class:facebook|10000|\n",
      "|  class:netflix|10000|\n",
      "|     class:ebay|10000|\n",
      "|  class:spotify|10000|\n",
      "| class:linkedin|10000|\n",
      "|  class:youtube|10000|\n",
      "|     class:bing|10000|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "web_services.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade98475-86ae-4f66-b53e-d95cfab40b35",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be7f04f-6b76-41ee-a296-4d01b26dde6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify TCP connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097f53d4-d313-43ab-a1be-97618c301d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataframe into train-set and test-set (75, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99e5e64b-266b-470e-9362-158ecfd277d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainValidation, test = df.randomSplit([0.75, 0.25], 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107af411-c296-4f83-98c5-a44d3534dec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00f7c901-33d7-43d6-ab6a-60ac1860962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2aa8777e-3ed1-4f73-a8b7-7751668a8d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features\n",
    "feat_cols = ['c_bytes_uniq:7', 's_bytes_uniq:21', 'c_pkts_data:8', 's_pkts_data:22']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b23a2fbc-efb4-4652-9cf7-d5ecebddef41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Preprocess TrainValidation set\n",
    "# Vector Assembler\n",
    "va = VectorAssembler(inputCols=feat_cols, outputCol='features')\n",
    "vDF = va.transform(trainValidation)\n",
    "# Convert string to index for target column\n",
    "indexer = StringIndexer(inputCol=\"class:207\", outputCol=\"label\")\n",
    "indexerModel = indexer.fit(vDF)\n",
    "indexedDF = indexerModel.transform(vDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56a7aa82-23dc-4c31-8bdb-ed76e885f6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Test set\n",
    "testVDF = va.transform(test)\n",
    "testIndexedDF = indexerModel.transform(testVDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba7650c-d339-4227-8237-6e0ecb9ed6a6",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848f7f8d-a867-46ca-b060-92ca8bdb7b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For classification, I am going to use Decision Tree model and Random Forest model\n",
    "# In order to compare how much time do these models take to train the I will import time to compare them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5021d9f4-82f6-4912-8e7a-97c2cf47c696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7d96e43-3e5d-4fbf-bef2-d392a936c225",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It takes 42.52218413352966 seconds\n"
     ]
    }
   ],
   "source": [
    "# 1. DECISION TREE CLASSIFIER\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", maxDepth=20)\n",
    "start_time = time.time()\n",
    "dtModel = dt.fit(indexedDF)\n",
    "stop_time = time.time()\n",
    "print(f'It takes {stop_time - start_time} seconds')\n",
    "finalDFdt = dtModel.transform(indexedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44b68657-8f7b-4242-b6c5-e7a969e0590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDFdt = dtModel.transform(testIndexedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa8a5635-a2b8-4d8b-a842-12b479deee55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 124:>                                                        (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It takes 61.193100452423096 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 2. RANDOM FOREST CLASSIFIER\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=20, maxDepth=20)\n",
    "start_time = time.time()\n",
    "rfModel = rf.fit(indexedDF)\n",
    "stop_time = time.time()\n",
    "print(f'It takes {stop_time - start_time} seconds')\n",
    "finalDFrf = rfModel.transform(indexedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b67f608-8664-440d-b654-e24e61ebf933",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDFrf = rfModel.transform(testIndexedDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb0ec4b-326c-4e64-a549-d496fbfb0a87",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0505bbaa-0bc1-41d1-ae26-613df162f8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the performance of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e044e1-227c-4422-b322-f524e9b68cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The result shows that Random Forest classifies data a little bit easier, because the precision of \n",
    "its classes are more diverse (0.50, 0.84) and this range is smaller for Decision Tree (0.50, 0.79).\n",
    "For train set, Decision Tree classifier's accuracy is a little bit more than Random Forest Classifier \n",
    "but in the test set, the accuracy of Random Forest is a little more than Decision Tree.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f291eabd-bd60-41be-be0a-eec57914274a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Decision Tree model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8467097-0eb8-417e-b4a7-180c5eee7659",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "151936ed-c225-49b7-96c1-19625a1c9f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b4898c4-9ddf-4bc1-b50a-f1eb04f0625e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global accuracy on the TrainValidation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "61d4cd03-d421-4979-9417-411ec6aa924f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 131:============================>                            (1 + 1) / 2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decition Tree Train Model:\t accuracy = 0.7894673736377927\n",
      "Random Forest Train Model:\t accuracy = 0.7818869734352935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(f'Decition Tree Train Model:\\t accuracy = {accuracy.evaluate(finalDFdt)}\\nRandom Forest Train Model:\\t accuracy = {accuracy.evaluate(finalDFrf)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf92d8ff-cb02-4a93-a4f9-3acf84e11097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global accuracy on the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb3fa7ef-9236-4fc3-9b14-9d53dcd10960",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 147:============================>                            (1 + 1) / 2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decition Tree Train Model:\t accuracy = 0.6938006255513673\n",
      "Random Forest Train Model:\t accuracy = 0.7055898628598926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(f'Decition Tree Train Model:\\t accuracy = {accuracy.evaluate(testDFdt)}\\nRandom Forest Train Model:\\t accuracy = {accuracy.evaluate(testDFrf)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e0f73d6c-6805-4086-ae2e-35f9180f64bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtTestRDD = testDFdt.select(\"prediction\", \"label\").rdd.map(lambda x: (float(x[0]), float(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc9a38c2-b6d6-4ce8-a46e-1bfeca930298",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfTestRDD = testDFrf.select(\"prediction\", \"label\").rdd.map(lambda x: (float(x[0]), float(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31c0a1e9-b463-4305-ad8f-edb7dc53b239",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e088018e-3e0a-40f8-9fc5-729e687a6916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_calculator(x):\n",
    "    metrics = MulticlassMetrics(x)\n",
    "    precision = metrics.precision()\n",
    "    recall = metrics.recall()\n",
    "    f1Score = metrics.fMeasure\n",
    "    labels = x.map(lambda a: a[1]).distinct().collect()\n",
    "    print(\"Class \\t Precision \\t\\t Recall \\t\\t F1Score\")\n",
    "    for label in sorted(labels):\n",
    "        print(f'{label},\\t {metrics.precision(label)},\\t {metrics.recall(label)},\\t {metrics.fMeasure(label, beta=0.1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7106b697-7f99-4097-bf89-fe58ea97d668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class \t Precision \t\t Recall \t\t F1Score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 163:============================>                            (1 + 1) / 2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0,\t 0.6794921123509042,\t 0.7376775271512114,\t 0.680023180095618\n",
      "1.0,\t 0.6761115954664342,\t 0.6372226787181594,\t 0.6757033049509563\n",
      "2.0,\t 0.7424892703862661,\t 0.6316430020283975,\t 0.7412014234204511\n",
      "3.0,\t 0.670468948035488,\t 0.6404358353510896,\t 0.6701577904322303\n",
      "4.0,\t 0.8008057296329454,\t 0.7150279776179057,\t 0.7998556896353286\n",
      "5.0,\t 0.7561613144137416,\t 0.8074162679425837,\t 0.7566368734924604\n",
      "6.0,\t 0.718683197947841,\t 0.6702551834130781,\t 0.7181694358904944\n",
      "7.0,\t 0.8450230995380092,\t 0.7980959936533122,\t 0.844531441561626\n",
      "8.0,\t 0.5014416146083613,\t 0.8155529503712388,\t 0.5033611217908153\n",
      "9.0,\t 0.697817571348629,\t 0.48540288049824837,\t 0.6948071650420092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dtTestMetrics = metrics_calculator(dtTestRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b7237b18-b787-4cee-87cb-7a3364a1a3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class \t Precision \t\t Recall \t\t F1Score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 171:============================>                            (1 + 1) / 2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0,\t 0.7344537815126051,\t 0.7301587301587301,\t 0.7344110085942245\n",
      "1.0,\t 0.7387127761767531,\t 0.6318816762530813,\t 0.7374782798598517\n",
      "2.0,\t 0.785254824344384,\t 0.6438133874239351,\t 0.7835504607337521\n",
      "3.0,\t 0.6723577235772358,\t 0.6674737691686844,\t 0.6723090172973061\n",
      "4.0,\t 0.8050847457627118,\t 0.7214228617106315,\t 0.8041614101331264\n",
      "5.0,\t 0.7290552584670231,\t 0.8153907496012759,\t 0.7298203584350973\n",
      "6.0,\t 0.7265917602996255,\t 0.6961722488038278,\t 0.72627755263418\n",
      "7.0,\t 0.862910381543922,\t 0.7715192383974613,\t 0.8618995178153834\n",
      "8.0,\t 0.5024043966109457,\t 0.8573661586557249,\t 0.5044723044946148\n",
      "9.0,\t 0.6933471933471933,\t 0.5192681977423121,\t 0.6910534495227446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rfTestMetrics = metrics_calculator(rfTestRDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fe32f7-a103-441b-9966-d312863b3c55",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319b62ff-2d20-44bf-a7a3-f73b4a18b87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7a68e4-f1f0-4ab4-8e3a-484dbf788b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am going to use CrossValidation and ParamGridBuilder for tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78bd8f4f-c0a8-4aa9-a4e2-975ef64738a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.tuning import ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "79ecca5e-5216-445c-9c4c-a063956633a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Decision Tree parameter Tuning\n",
    "dtParamGrid = ParamGridBuilder().addGrid(dt.maxDepth, [15, 20, 25]).addGrid(dt.impurity, [\"Gini\", \"Entropy\"]).build()\n",
    "# CrossValidation\n",
    "dtCv = CrossValidator(estimator=dt, evaluator=accuracy, estimatorParamMaps=dtParamGrid, numFolds=3)\n",
    "dtCvModel = dtCv.fit(indexedDF)\n",
    "dtFinalDF = dtCvModel.transform(indexedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eb89748b-18ec-475f-b90c-865541d4d4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "08185fb4-db83-433b-9682-785f06d3bb61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='DecisionTreeClassifier_83c6b6ced5c4', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       " Param(parent='DecisionTreeClassifier_83c6b6ced5c4', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'Gini'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyze the best parameter of Decision Tree Classifier\n",
    "dtCvModel.getEstimatorParamMaps()[np.argmax(dtCvModel.avgMetrics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "693fbdcf-1ca8-4b07-9ece-8307ccc5cc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Random Forest parameter Tuning\n",
    "rfParamGrid = ParamGridBuilder().addGrid(rf.maxDepth, [15, 20, 25]).addGrid(rf.impurity, [\"Gini\", \"Entropy\"]).addGrid(rf.numTrees, [15, 20, 25]).build()\n",
    "# CrossValidation\n",
    "rfCv = CrossValidator(estimator=rf, evaluator=accuracy, estimatorParamMaps=rfParamGrid, numFolds=3)\n",
    "rfCvModel = rfCv.fit(indexedDF)\n",
    "rfFinalDF = rfCvModel.transform(indexedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6599236b-db98-442d-8be9-70b94af6a19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='RandomForestClassifier_e5cd46576df4', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       " Param(parent='RandomForestClassifier_e5cd46576df4', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'Entropy',\n",
       " Param(parent='RandomForestClassifier_e5cd46576df4', name='numTrees', doc='Number of trees to train (>= 1).'): 25}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyze the best parameter of Decision Tree Classifier\n",
    "rfCvModel.getEstimatorParamMaps()[np.argmax(rfCvModel.avgMetrics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b4f059ae-e9ef-4c3b-94c9-7e048f2a9d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7894673736377927"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate best Decision Tree model accuracy\n",
    "bestDT = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", maxDepth=20, impurity=\"Gini\")\n",
    "bestDTModel = bestDT.fit(indexedDF)\n",
    "bestDTFinal = bestDTModel.transform(indexedDF)\n",
    "accuracy.evaluate(bestDTFinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aea14d93-1f6b-4f48-8b0d-04a17f34224f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7818869734352935"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate best Random Forest model accuracy\n",
    "bestRF = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", maxDepth=20, impurity=\"Gini\", numTrees=20)\n",
    "bestRFModel = bestRF.fit(indexedDF)\n",
    "bestRFFinal = bestRFModel.transform(indexedDF)\n",
    "accuracy.evaluate(bestRFFinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "426eea08-54a2-4ec6-a238-374eebaa52c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6938006255513673"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate best Decision Tree model accuracy test set\n",
    "bestDTFinaltest = bestDTModel.transform(testIndexedDF)\n",
    "accuracy.evaluate(bestDTFinaltest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "30da2efd-6539-4e22-8104-e7344ceb9de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7055898628598926"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate best Random Forest model accuracy test set\n",
    "bestRFFinaltest = bestRFModel.transform(testIndexedDF)\n",
    "accuracy.evaluate(bestRFFinaltest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ca6e53-3bff-46f9-b58d-6d10c7b9e5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It shows that the best possible model is Random Forest and its accuracy is about 70% "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781827e6-5891-4493-a31b-354ad8c1592b",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8cc7b9-15b6-48b3-ae33-cf289af27e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73357e71-58d6-47bc-9883-32ed6d1554d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am going to use k-means model and Gaussian mixture model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1afd735-3f1b-46d3-b392-8ef6d4d736ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate how many distinct IPs (users) we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "320e4ab2-f9ba-4477-ad71-17663a310119",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "clients = df.select(\"#31#c_ip:1\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2d9a6512-6772-4b40-86ed-c21eacdbafc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3844\n"
     ]
    }
   ],
   "source": [
    "print(clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2efbaf3-65b8-4f70-8703-9fb25387e51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the top-5 most active users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "691e1525-128a-41b6-b043-3c4288de76ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "connections = df.groupBy(\"#31#c_ip:1\").agg({\"#31#c_ip:1\": \"count\", \"c_bytes_all:9\":\"sum\", \"s_bytes_all:23\":\"sum\", \"s_bytes_retx:25\":\"sum\", \"s_rtt_avg:52\":\"avg\", \"s_first:33\":\"avg\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "930555a9-dcfa-4241-a881-8d5f1c59e0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3871:============================================>       (171 + 2) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+-----------------+------------------+-------------------+--------------------+------------------+\n",
      "|    #31#c_ip:1| avg(s_rtt_avg:52)|count(#31#c_ip:1)|   avg(s_first:33)|sum(s_bytes_all:23)|sum(s_bytes_retx:25)|sum(c_bytes_all:9)|\n",
      "+--------------+------------------+-----------------+------------------+-------------------+--------------------+------------------+\n",
      "| 246.25.63.193|126.04335648340408|             1175|57.096006808510644|            3273754|              170919|           2596746|\n",
      "|246.25.221.106| 42.48682521290321|              620|176.24669516129038|            8000015|               31258|           8934440|\n",
      "|  180.102.5.86|30.208663604166667|              528|  95.7006685606061|             776618|                 560|           1946611|\n",
      "|  246.25.63.82|103.03908910739855|              419| 292.7211861575179|           62219033|             2091264|          10775700|\n",
      "|  180.102.5.42| 64.18118633250616|              403|180.22686352357326|           13021759|               90956|           4376418|\n",
      "+--------------+------------------+-----------------+------------------+-------------------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "connectionOrdered = connections.sort(\"count(#31#c_ip:1)\", ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c2db0a-5f5c-4a1a-9d46-bc6a14b6fe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average number of connections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2dd540e-3e95-4722-94e1-ec6ed972c699",
   "metadata": {},
   "outputs": [],
   "source": [
    "connectionsAvg = connections.agg({\"count(#31#c_ip:1)\":\"avg\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4ee488e4-5c43-4ed4-9b05-e76bf529ba4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3873:==========================================>         (162 + 3) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|avg(count(#31#c_ip:1))|\n",
      "+----------------------+\n",
      "|    26.014568158168576|\n",
      "+----------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "connectionsAvg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69b63d8d-5fcd-4e4e-91d4-f4b7da600069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features selection\n",
    "feat_cols_cluster = ['count(#31#c_ip:1)', 'sum(s_bytes_all:23)', 'sum(s_bytes_retx:25)', 'sum(c_bytes_all:9)', 'avg(s_rtt_avg:52)', 'avg(s_first:33)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2c564e1-62f7-44c7-957c-8c8bf0ddcd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "va_cluster = VectorAssembler(inputCols=feat_cols_cluster, outputCol=\"features\")\n",
    "assembledDF = va_cluster.transform(connections)\n",
    "# Scaler\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=True, withMean=True)\n",
    "scalerModel = scaler.fit(assembledDF)\n",
    "scaledDF = scalerModel.transform(assembledDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7883b90-f258-4bc8-8107-0fb6713b6b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the K-Means model\n",
    "from pyspark.ml.clustering import KMeans\n",
    "kmeans = KMeans(k=10, featuresCol=\"scaledFeatures\")\n",
    "kmeansModel = kmeans.fit(scaledDF)\n",
    "kmeansPredictionsDF = kmeansModel.transform(scaledDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fcf381f6-a869-47de-8238-d4ea06478f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the GMM model\n",
    "from pyspark.ml.clustering import GaussianMixture\n",
    "gmm = GaussianMixture(k=10, featuresCol=\"scaledFeatures\")\n",
    "gmmModel = gmm.fit(scaledDF)\n",
    "gmmPredictionsDF = gmmModel.transform(scaledDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bfad5ac-a9cc-42ae-b5fa-69946c55b10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "evaluator = ClusteringEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "84beb866-e59d-45d4-9436-e4d35c954c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette with squared euclidean distance = 0.12522028393706328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4951:===================================================>(198 + 2) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE:  6406.865780093279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Evaluate K-Means performance \n",
    "silhouetteKMeans = evaluator.evaluate(kmeansPredictionsDF)\n",
    "print(\"Silhouette with squared euclidean distance = \" + str(silhouette))\n",
    "print(\"SSE: \",kmeansModel.computeCost(kmeansPredictionsDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cca8f3d2-4f96-43a2-a32a-ef0a1706b976",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4956:=========================================>          (158 + 4) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette with squared euclidean distance = 0.12522028393706328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Evaluate GMM performance \n",
    "silhouetteGMM = evaluator.evaluate(gmmPredictionsDF)\n",
    "print(\"Silhouette with squared euclidean distance = \" + str(silhouette))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bbc23db-400a-4632-bfa9-8fae94c3207b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 497:=============================================>       (172 + 4) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette with squared euclidean distance = 0.9916145915641448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Tune K-means Parameters\n",
    "kmeansBest = KMeans(k=3, featuresCol=\"scaledFeatures\", initSteps=10, maxIter=25)\n",
    "kmeansModelBest = kmeansBest.fit(scaledDF)\n",
    "kmeansPredictionsBest = kmeansModelBest.transform(scaledDF)\n",
    "silhouetteBKM = evaluator.evaluate(kmeansPredictionsBest)\n",
    "print(\"Silhouette with squared euclidean distance = \" + str(silhouetteBKM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc777844-5d06-4980-bcbc-ce800399485b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 526:================================>                        (4 + 3) / 7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette with squared euclidean distance = 0.7156195042662563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Tune the GMM parameters\n",
    "gmmBest = GaussianMixture(k=3, featuresCol=\"scaledFeatures\", maxIter=5)\n",
    "gmmModelBest = gmmBest.fit(scaledDF)\n",
    "gmmPredictionsBest = gmmModelBest.transform(scaledDF)\n",
    "silhouetteBGMM = evaluator.evaluate(gmmPredictionsBest)\n",
    "print(\"Silhouette with squared euclidean distance = \" + str(silhouetteBGMM))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Yarn)",
   "language": "python",
   "name": "pyspark_yarn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
